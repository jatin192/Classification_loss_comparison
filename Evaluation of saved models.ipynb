{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "341d4ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.models as models\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as metrics\n",
    "import pickle\n",
    "import torchvision\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8ec22b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"6\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "157dab2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(\n",
    "    saved_path=\"saved_models/resnet18.pt\",\n",
    "    lr=0.001, \n",
    "    EPOCHS = 5,\n",
    "    BATCH_SIZE = 8,\n",
    "    IMAGE_SIZE = 128,\n",
    "    TRAIN_VALID_SPLIT = 0.2,\n",
    "    device=device,\n",
    "    SEED = 42,\n",
    "    pin_memory=True,\n",
    "    num_workers=2,\n",
    "    USE_AMP = True,\n",
    "    channels_last=False)\n",
    "\n",
    "random.seed(config['SEED'])\n",
    "np.random.seed(config['SEED'])\n",
    "torch.manual_seed(config['SEED'])\n",
    "torch.cuda.manual_seed(config['SEED'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "335b4526",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmarks = True\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "\n",
    "# The flag below controls whether to allow TF32 on cuDNN. This flag defaults to True.\n",
    "torch.backends.cudnn.allow_tf32 = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22427715",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop((config['IMAGE_SIZE'],config['IMAGE_SIZE'])),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomAutocontrast(0.5),\n",
    "        transforms.RandomRotation(20),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((config['IMAGE_SIZE'],config['IMAGE_SIZE'])),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((config['IMAGE_SIZE'],config['IMAGE_SIZE'])),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753430df",
   "metadata": {},
   "source": [
    "# Triplet Loss Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f22b20db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "a_file = open(\"dataset.pkl\", \"rb\")\n",
    "dataset = pickle.load(a_file)\n",
    "print(len(set(dataset['labels'][:500])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78a8dedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom_data(Dataset):\n",
    "    def __init__(self, dataset, transform = data_transforms, train=True):\n",
    "        super(Custom_data,self).__init__()\n",
    "        self.train_transforms = transform['test']\n",
    "        self.test_transforms = transform['test']\n",
    "        self.is_train = train\n",
    "        self.to_pil = transforms.ToPILImage()\n",
    "        \n",
    "        if self.is_train:\n",
    "            self.images = dataset['images']\n",
    "            self.labels = np.array(dataset['labels'])\n",
    "            self.index = np.array(list(range(len(self.labels))))\n",
    "        \n",
    "        else:\n",
    "            self.images = dataset['images']\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        anchor_img = self.images[item]\n",
    "        \n",
    "        if self.is_train:\n",
    "            anchor_label = self.labels[item]\n",
    "            positive_list = self.index[self.index!=item][self.labels[self.index!=item]==anchor_label]\n",
    "\n",
    "            positive_item = random.choice(positive_list)\n",
    "            positive_img = self.images[positive_item]\n",
    "\n",
    "            negative_list = self.index[self.index!=item][self.labels[self.index!=item]!=anchor_label]\n",
    "            negative_item = random.choice(negative_list)\n",
    "            negative_img = self.images[negative_item]\n",
    "\n",
    "            if self.train_transforms:\n",
    "                anchor_img = self.train_transforms(self.to_pil(anchor_img))\n",
    "                positive_img = self.train_transforms(self.to_pil(positive_img))\n",
    "                negative_img = self.train_transforms(self.to_pil(negative_img))\n",
    "\n",
    "                return anchor_img, positive_img, negative_img, anchor_label\n",
    "        \n",
    "        else:\n",
    "            if self.transform:\n",
    "                anchor_img = self.test_transforms(self.to_pil(anchor_img))\n",
    "            return anchor_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b57eddcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 3, 128, 128]) torch.Size([8, 3, 128, 128]) torch.Size([8, 3, 128, 128]) torch.Size([8])\n",
      "12500\n"
     ]
    }
   ],
   "source": [
    "train_ds = Custom_data(dataset, train=True)\n",
    "train_loader = DataLoader(train_ds, batch_size=config['BATCH_SIZE'], shuffle=True,pin_memory = config['pin_memory'])\n",
    "a = iter(train_loader)\n",
    "b = next(a)\n",
    "print(b[0].shape, b[1].shape, b[2].shape, b[3].shape)\n",
    "print(len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d9295d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return x\n",
    "\n",
    "# Reloading saved weights of the model.\n",
    "densenet = models.densenet121(pretrained = True)\n",
    "densenet.classifier = Identity()\n",
    "model = densenet\n",
    "model = model.to(config['device'])\n",
    "model.load_state_dict(torch.load('saved_models/densenet121_triplet.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2f9ae23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12500"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df1283f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4800, 1024) (4800,)\n"
     ]
    }
   ],
   "source": [
    "# storing the feature embedding vector in train_results list\n",
    "train_results = []\n",
    "labels = []\n",
    "count = 0\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for img, _, _, label in train_loader:\n",
    "        if count<600: # considering 600 batches\n",
    "            train_results.append(model(img.to(device)).cpu().numpy())\n",
    "            labels.append(label)\n",
    "            count+=1\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "train_results = np.concatenate(train_results)\n",
    "labels = np.concatenate(labels)\n",
    "print(train_results.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "88ad88a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "l = (len(labels)*8)//10\n",
    "x_train,y_train = train_results[:l],labels[:l]\n",
    "x_test,y_test = train_results[l:],labels[l:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "087f55c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.5\n",
      "0:\tlearn: 5.1245961\ttotal: 3.32s\tremaining: 5m 28s\n",
      "1:\tlearn: 4.9425648\ttotal: 6.6s\tremaining: 5m 23s\n",
      "2:\tlearn: 4.7737838\ttotal: 9.79s\tremaining: 5m 16s\n",
      "3:\tlearn: 4.6494719\ttotal: 13.9s\tremaining: 5m 33s\n",
      "4:\tlearn: 4.5194368\ttotal: 17.8s\tremaining: 5m 38s\n",
      "5:\tlearn: 4.3885183\ttotal: 21.4s\tremaining: 5m 36s\n",
      "6:\tlearn: 4.2911668\ttotal: 24.8s\tremaining: 5m 30s\n",
      "7:\tlearn: 4.1930719\ttotal: 28s\tremaining: 5m 22s\n",
      "8:\tlearn: 4.0866090\ttotal: 31.7s\tremaining: 5m 20s\n",
      "9:\tlearn: 3.9937066\ttotal: 34.9s\tremaining: 5m 14s\n",
      "10:\tlearn: 3.9055630\ttotal: 38.4s\tremaining: 5m 10s\n",
      "11:\tlearn: 3.8164290\ttotal: 41.7s\tremaining: 5m 5s\n",
      "12:\tlearn: 3.7296395\ttotal: 45.1s\tremaining: 5m 1s\n",
      "13:\tlearn: 3.6790027\ttotal: 48.8s\tremaining: 4m 59s\n",
      "14:\tlearn: 3.5881671\ttotal: 52.7s\tremaining: 4m 58s\n",
      "15:\tlearn: 3.4957695\ttotal: 56.2s\tremaining: 4m 55s\n",
      "16:\tlearn: 3.4166463\ttotal: 59.6s\tremaining: 4m 50s\n",
      "17:\tlearn: 3.3553706\ttotal: 1m 2s\tremaining: 4m 45s\n",
      "18:\tlearn: 3.2985342\ttotal: 1m 5s\tremaining: 4m 40s\n",
      "19:\tlearn: 3.2196700\ttotal: 1m 9s\tremaining: 4m 37s\n",
      "20:\tlearn: 3.1726272\ttotal: 1m 12s\tremaining: 4m 33s\n",
      "21:\tlearn: 3.1349462\ttotal: 1m 15s\tremaining: 4m 29s\n",
      "22:\tlearn: 3.1042190\ttotal: 1m 19s\tremaining: 4m 25s\n",
      "23:\tlearn: 3.0480605\ttotal: 1m 22s\tremaining: 4m 20s\n",
      "24:\tlearn: 3.0281407\ttotal: 1m 26s\tremaining: 4m 18s\n",
      "25:\tlearn: 2.9803501\ttotal: 1m 29s\tremaining: 4m 16s\n",
      "26:\tlearn: 2.9287878\ttotal: 1m 33s\tremaining: 4m 12s\n",
      "27:\tlearn: 2.8881962\ttotal: 1m 36s\tremaining: 4m 8s\n",
      "28:\tlearn: 2.8570481\ttotal: 1m 39s\tremaining: 4m 4s\n",
      "29:\tlearn: 2.8349659\ttotal: 1m 42s\tremaining: 3m 59s\n",
      "30:\tlearn: 2.8127491\ttotal: 1m 46s\tremaining: 3m 56s\n",
      "31:\tlearn: 2.7858265\ttotal: 1m 49s\tremaining: 3m 52s\n",
      "32:\tlearn: 2.7484007\ttotal: 1m 52s\tremaining: 3m 48s\n",
      "33:\tlearn: 2.7145465\ttotal: 1m 55s\tremaining: 3m 44s\n",
      "34:\tlearn: 2.6799968\ttotal: 1m 58s\tremaining: 3m 40s\n",
      "35:\tlearn: 2.6411856\ttotal: 2m 2s\tremaining: 3m 37s\n",
      "36:\tlearn: 2.6127580\ttotal: 2m 6s\tremaining: 3m 34s\n",
      "37:\tlearn: 2.5789405\ttotal: 2m 9s\tremaining: 3m 31s\n",
      "38:\tlearn: 2.5532873\ttotal: 2m 13s\tremaining: 3m 28s\n",
      "39:\tlearn: 2.5095372\ttotal: 2m 16s\tremaining: 3m 24s\n",
      "40:\tlearn: 2.4879153\ttotal: 2m 19s\tremaining: 3m 20s\n",
      "41:\tlearn: 2.4577694\ttotal: 2m 23s\tremaining: 3m 17s\n",
      "42:\tlearn: 2.4048238\ttotal: 2m 26s\tremaining: 3m 14s\n",
      "43:\tlearn: 2.3740758\ttotal: 2m 29s\tremaining: 3m 10s\n",
      "44:\tlearn: 2.3311540\ttotal: 2m 32s\tremaining: 3m 6s\n",
      "45:\tlearn: 2.3119761\ttotal: 2m 35s\tremaining: 3m 3s\n",
      "46:\tlearn: 2.2972072\ttotal: 2m 40s\tremaining: 3m\n",
      "47:\tlearn: 2.2869990\ttotal: 2m 44s\tremaining: 2m 58s\n",
      "48:\tlearn: 2.2509615\ttotal: 2m 48s\tremaining: 2m 54s\n",
      "49:\tlearn: 2.2362349\ttotal: 2m 51s\tremaining: 2m 51s\n",
      "50:\tlearn: 2.2164949\ttotal: 2m 54s\tremaining: 2m 47s\n",
      "51:\tlearn: 2.2076887\ttotal: 2m 58s\tremaining: 2m 44s\n",
      "52:\tlearn: 2.1706210\ttotal: 3m 1s\tremaining: 2m 40s\n",
      "53:\tlearn: 2.1506232\ttotal: 3m 4s\tremaining: 2m 37s\n",
      "54:\tlearn: 2.1226691\ttotal: 3m 7s\tremaining: 2m 33s\n",
      "55:\tlearn: 2.0908769\ttotal: 3m 11s\tremaining: 2m 30s\n",
      "56:\tlearn: 2.0623979\ttotal: 3m 14s\tremaining: 2m 26s\n",
      "57:\tlearn: 2.0327189\ttotal: 3m 18s\tremaining: 2m 23s\n",
      "58:\tlearn: 2.0091668\ttotal: 3m 22s\tremaining: 2m 20s\n",
      "59:\tlearn: 1.9965250\ttotal: 3m 25s\tremaining: 2m 17s\n",
      "60:\tlearn: 1.9775284\ttotal: 3m 28s\tremaining: 2m 13s\n",
      "61:\tlearn: 1.9566170\ttotal: 3m 31s\tremaining: 2m 9s\n",
      "62:\tlearn: 1.9359979\ttotal: 3m 35s\tremaining: 2m 6s\n",
      "63:\tlearn: 1.9174364\ttotal: 3m 38s\tremaining: 2m 3s\n",
      "64:\tlearn: 1.8876755\ttotal: 3m 41s\tremaining: 1m 59s\n",
      "65:\tlearn: 1.8728847\ttotal: 3m 45s\tremaining: 1m 56s\n",
      "66:\tlearn: 1.8502220\ttotal: 3m 48s\tremaining: 1m 52s\n",
      "67:\tlearn: 1.8177416\ttotal: 3m 52s\tremaining: 1m 49s\n",
      "68:\tlearn: 1.7906974\ttotal: 3m 55s\tremaining: 1m 45s\n",
      "69:\tlearn: 1.7628340\ttotal: 3m 59s\tremaining: 1m 42s\n",
      "70:\tlearn: 1.7465535\ttotal: 4m 3s\tremaining: 1m 39s\n",
      "71:\tlearn: 1.7137869\ttotal: 4m 6s\tremaining: 1m 35s\n",
      "72:\tlearn: 1.6779182\ttotal: 4m 9s\tremaining: 1m 32s\n",
      "73:\tlearn: 1.6505709\ttotal: 4m 12s\tremaining: 1m 28s\n",
      "74:\tlearn: 1.6246760\ttotal: 4m 16s\tremaining: 1m 25s\n",
      "75:\tlearn: 1.6125588\ttotal: 4m 19s\tremaining: 1m 21s\n",
      "76:\tlearn: 1.5958782\ttotal: 4m 22s\tremaining: 1m 18s\n",
      "77:\tlearn: 1.5705601\ttotal: 4m 25s\tremaining: 1m 15s\n",
      "78:\tlearn: 1.5429788\ttotal: 4m 29s\tremaining: 1m 11s\n",
      "79:\tlearn: 1.5230778\ttotal: 4m 33s\tremaining: 1m 8s\n",
      "80:\tlearn: 1.5116084\ttotal: 4m 37s\tremaining: 1m 5s\n",
      "81:\tlearn: 1.4962935\ttotal: 4m 40s\tremaining: 1m 1s\n",
      "82:\tlearn: 1.4796599\ttotal: 4m 43s\tremaining: 58.1s\n",
      "83:\tlearn: 1.4593512\ttotal: 4m 47s\tremaining: 54.7s\n",
      "84:\tlearn: 1.4535375\ttotal: 4m 50s\tremaining: 51.2s\n",
      "85:\tlearn: 1.4397539\ttotal: 4m 53s\tremaining: 47.8s\n",
      "86:\tlearn: 1.4243494\ttotal: 4m 57s\tremaining: 44.4s\n",
      "87:\tlearn: 1.4064915\ttotal: 5m\tremaining: 41s\n",
      "88:\tlearn: 1.3850508\ttotal: 5m 4s\tremaining: 37.6s\n",
      "89:\tlearn: 1.3696571\ttotal: 5m 8s\tremaining: 34.2s\n",
      "90:\tlearn: 1.3502907\ttotal: 5m 11s\tremaining: 30.8s\n",
      "91:\tlearn: 1.3377004\ttotal: 5m 15s\tremaining: 27.4s\n",
      "92:\tlearn: 1.3177971\ttotal: 5m 18s\tremaining: 24s\n",
      "93:\tlearn: 1.3085365\ttotal: 5m 22s\tremaining: 20.6s\n",
      "94:\tlearn: 1.2927450\ttotal: 5m 25s\tremaining: 17.2s\n",
      "95:\tlearn: 1.2755414\ttotal: 5m 29s\tremaining: 13.7s\n",
      "96:\tlearn: 1.2704932\ttotal: 5m 32s\tremaining: 10.3s\n",
      "97:\tlearn: 1.2470804\ttotal: 5m 35s\tremaining: 6.86s\n",
      "98:\tlearn: 1.2263109\ttotal: 5m 39s\tremaining: 3.42s\n",
      "99:\tlearn: 1.2043125\ttotal: 5m 43s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7f3f2fd4ec18>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Catboost classifier\n",
    "# !pip install catboost\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "cat = CatBoostClassifier(iterations=100)\n",
    "cat.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "73265351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.408125\n",
      "precision_score:  0.4783128081847848\n",
      "recall_score:  0.408125\n",
      "f1_score:  0.40659339871759487\n"
     ]
    }
   ],
   "source": [
    "y_pred = cat.predict(x_test)\n",
    "print('accuracy',metrics.accuracy_score(y_test,y_pred))\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
    "                                                          \n",
    "print(\"precision_score: \",precision)\n",
    "print(\"recall_score: \",recall)\n",
    "print(\"f1_score: \",f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b076ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2d4b7e0",
   "metadata": {},
   "source": [
    "# Center Loss Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1cdc19d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n"
     ]
    }
   ],
   "source": [
    "my_path = '../dataset/miniimgnet_dlassignment/tinyimgnet/tiny-imagenet-200/train/'\n",
    "images = torchvision.datasets.ImageFolder(root=my_path,transform=data_transforms['train'])\n",
    "print(len(images))\n",
    "train_data,valid_data = torch.utils.data.dataset.random_split(images,[90000,10000])\n",
    "\n",
    "\n",
    "train_dl = torch.utils.data.DataLoader(dataset=train_data,batch_size=32,shuffle=True, num_workers = config['num_workers'],\n",
    "                                          pin_memory = config['pin_memory'])\n",
    "valid_dl = torch.utils.data.DataLoader(dataset = valid_data,batch_size=32,shuffle=True, num_workers = config['num_workers'],\n",
    "                                          pin_memory = config['pin_memory'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66dbeff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CenterLoss(nn.Module):\n",
    "    def __init__(self, num_classes=200, feat_dim=200, use_gpu=True):\n",
    "        super(CenterLoss, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.feat_dim = feat_dim\n",
    "        self.use_gpu = use_gpu\n",
    "\n",
    "        if self.use_gpu:\n",
    "            self.centers = nn.Parameter(torch.randn(self.num_classes, self.feat_dim).cuda())\n",
    "        else:\n",
    "            self.centers = nn.Parameter(torch.randn(self.num_classes, self.feat_dim))\n",
    "\n",
    "    def forward(self, x, labels):\n",
    "        batch_size = x.size(0)\n",
    "        distmat = torch.pow(x, 2).sum(dim=1, keepdim=True).expand(batch_size, self.num_classes) + \\\n",
    "                  torch.pow(self.centers, 2).sum(dim=1, keepdim=True).expand(self.num_classes, batch_size).t()\n",
    "        distmat.addmm_(1, -2, x, self.centers.t())\n",
    "\n",
    "        classes = torch.arange(self.num_classes).long()\n",
    "        if self.use_gpu: classes = classes.cuda()\n",
    "        labels = labels.unsqueeze(1).expand(batch_size, self.num_classes)\n",
    "        mask = labels.eq(classes.expand(batch_size, self.num_classes))\n",
    "\n",
    "        dist = distmat * mask.float()\n",
    "        loss = dist.clamp(min=1e-12, max=1e+12).sum() / batch_size\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c701bf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model,test_dl,test_data):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    total = 0\n",
    "    preds = []\n",
    "    pred_labels = []\n",
    "    labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "                for x,y in test_dl:\n",
    "                    x = x.to(config['device'])\n",
    "                    y = y.to(config['device']) #CHW --> #HWC\n",
    "                    valid_logits = model(x)\n",
    "                    predict_prob = F.softmax(valid_logits)\n",
    "                    _,predictions = predict_prob.max(1)\n",
    "                    predictions = predictions.to('cpu')\n",
    "\n",
    "                    _, valid_preds = torch.max(valid_logits, 1)\n",
    "                    valid_loss = criterion(valid_logits,y)\n",
    "                    running_loss += valid_loss.item() * x.size(0)\n",
    "                    running_corrects += torch.sum(valid_preds == y.data)\n",
    "                    total += y.size(0)\n",
    "                    predict_prob = predict_prob.to('cpu')\n",
    "\n",
    "                    pred_labels.extend(list(predictions.numpy()))\n",
    "                    preds.extend(list(predict_prob.numpy()))\n",
    "                    y = y.to('cpu')\n",
    "                    labels.extend(list(y.numpy()))\n",
    "\n",
    "    epoch_loss = running_loss / len(test_data)\n",
    "    epoch_acc = running_corrects.double() / len(test_data)\n",
    "    #print(\"Test Loss is {}\".format(epoch_loss))\n",
    "    print(\"Test Accuracy is {}\".format(epoch_acc.cpu()))\n",
    "    return np.array(labels),np.array(pred_labels),np.array(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ca6e876",
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet = models.densenet121(pretrained = True)\n",
    "densenet.classifier = nn.Linear(in_features = 1024, out_features = 200, bias = True)\n",
    "model = densenet\n",
    "model = model.to(config['device'])\n",
    "model.load_state_dict(torch.load('saved_models/densenet121_center.pt'))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7f1f2c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy is 0.3503\n"
     ]
    }
   ],
   "source": [
    "labels, pred_labels, preds = evaluation(model,valid_dl,valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ad1332e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_score:  0.3196631341429935\n",
      "recall_score:  0.3503\n",
      "f1_score:  0.31600115823036806\n"
     ]
    }
   ],
   "source": [
    "precision, recall, f1, _ = precision_recall_fscore_support(labels, pred_labels, average='weighted')\n",
    "\n",
    "print(\"precision_score: \",precision)\n",
    "print(\"recall_score: \",recall)\n",
    "print(\"f1_score: \",f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf76da89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "740accea",
   "metadata": {},
   "source": [
    "# Cross Entropy loss model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f0ccd2c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n"
     ]
    }
   ],
   "source": [
    "my_path = '../dataset/miniimgnet_dlassignment/tinyimgnet/tiny-imagenet-200/train/'\n",
    "images = torchvision.datasets.ImageFolder(root=my_path,transform=data_transforms['train'])\n",
    "print(len(images))\n",
    "train_data,valid_data = torch.utils.data.dataset.random_split(images,[90000,10000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f2f375da",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = torch.utils.data.DataLoader(dataset=train_data,batch_size=32,shuffle=True, num_workers = config['num_workers'],\n",
    "                                          pin_memory = config['pin_memory'])\n",
    "valid_dl = torch.utils.data.DataLoader(dataset = valid_data,batch_size=32,shuffle=True, num_workers = config['num_workers'],\n",
    "                                          pin_memory = config['pin_memory'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6dd5cc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model,test_dl,test_data):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    total = 0\n",
    "    preds = []\n",
    "    pred_labels = []\n",
    "    labels = []\n",
    "\n",
    "            # Disable gradient calculation for validation or inference using torch.no_rad()\n",
    "    with torch.no_grad():\n",
    "                for x,y in test_dl:\n",
    "                    x = x.to(config['device'])\n",
    "                    y = y.to(config['device']) #CHW --> #HWC\n",
    "                    valid_logits = model(x)\n",
    "                    predict_prob = F.softmax(valid_logits)\n",
    "                    _,predictions = predict_prob.max(1)\n",
    "                    predictions = predictions.to('cpu')\n",
    "\n",
    "                    _, valid_preds = torch.max(valid_logits, 1)\n",
    "                    valid_loss = criterion(valid_logits,y)\n",
    "                    running_loss += valid_loss.item() * x.size(0)\n",
    "                    running_corrects += torch.sum(valid_preds == y.data)\n",
    "                    total += y.size(0)\n",
    "                    predict_prob = predict_prob.to('cpu')\n",
    "\n",
    "                    pred_labels.extend(list(predictions.numpy()))\n",
    "                    preds.extend(list(predict_prob.numpy()))\n",
    "                    y = y.to('cpu')\n",
    "                    labels.extend(list(y.numpy()))\n",
    "\n",
    "    epoch_loss = running_loss / len(test_data)\n",
    "    epoch_acc = running_corrects.double() / len(test_data)\n",
    "    print(\"Test Loss is {}\".format(epoch_loss))\n",
    "    print(\"Test Accuracy is {}\".format(epoch_acc.cpu()))\n",
    "    return np.array(labels),np.array(pred_labels),np.array(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cdee5efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet = models.densenet121(pretrained = True)\n",
    "densenet.classifier = nn.Linear(in_features = 1024, out_features = 200, bias = True)\n",
    "model = densenet\n",
    "model = model.to(config['device'])\n",
    "model.load_state_dict(torch.load('saved_models/densenet121_crossentropy.pt'))\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8958f86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss is 1.9161838850021362\n",
      "Test Accuracy is 0.5405\n"
     ]
    }
   ],
   "source": [
    "labels, pred_labels, preds = evaluation(model,valid_dl,valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b7004235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_score:  0.5581511134618601\n",
      "recall_score:  0.5405\n",
      "f1_score:  0.5340788106109255\n"
     ]
    }
   ],
   "source": [
    "precision, recall, f1, _ = precision_recall_fscore_support(labels, pred_labels, average='weighted')\n",
    "\n",
    "print(\"precision_score: \",precision)\n",
    "print(\"recall_score: \",recall)\n",
    "print(\"f1_score: \",f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81591973",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
